{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment # 06"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objective: Perform initial data exploration to gain insights and understand the Titanic dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Titanic dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df = pd.read_csv('./datasets/titanic_dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display the first 5 rows of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows:\n",
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.2500   NaN        S  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3      0            113803  53.1000  C123        S  \n",
      "4      0            373450   8.0500   NaN        S  \n"
     ]
    }
   ],
   "source": [
    "print(\"First 5 rows:\")\n",
    "print(titanic_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display the last 5 rows of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Last 5 rows:\n",
      "     PassengerId  Survived  Pclass                                      Name  \\\n",
      "886          887         0       2                     Montvila, Rev. Juozas   \n",
      "887          888         1       1              Graham, Miss. Margaret Edith   \n",
      "888          889         0       3  Johnston, Miss. Catherine Helen \"Carrie\"   \n",
      "889          890         1       1                     Behr, Mr. Karl Howell   \n",
      "890          891         0       3                       Dooley, Mr. Patrick   \n",
      "\n",
      "        Sex   Age  SibSp  Parch      Ticket   Fare Cabin Embarked  \n",
      "886    male  27.0      0      0      211536  13.00   NaN        S  \n",
      "887  female  19.0      0      0      112053  30.00   B42        S  \n",
      "888  female   NaN      1      2  W./C. 6607  23.45   NaN        S  \n",
      "889    male  26.0      0      0      111369  30.00  C148        C  \n",
      "890    male  32.0      0      0      370376   7.75   NaN        Q  \n"
     ]
    }
   ],
   "source": [
    "print(\"\\nLast 5 rows:\")\n",
    "print(titanic_df.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the dimensions of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dimensions of the dataset: (891, 12)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nDimensions of the dataset:\", titanic_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify the data types of each feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId      int64\n",
      "Survived         int64\n",
      "Pclass           int64\n",
      "Name            object\n",
      "Sex             object\n",
      "Age            float64\n",
      "SibSp            int64\n",
      "Parch            int64\n",
      "Ticket          object\n",
      "Fare           float64\n",
      "Cabin           object\n",
      "Embarked        object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(titanic_df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Count of unique values in categorical features:\n",
      "Name        891\n",
      "Sex           2\n",
      "Ticket      681\n",
      "Cabin       147\n",
      "Embarked      3\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nCount of unique values in categorical features:\")\n",
    "print(titanic_df.select_dtypes(include='object').nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigate missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values for each feature:\n",
      "             Total  Percentage\n",
      "PassengerId      0    0.000000\n",
      "Survived         0    0.000000\n",
      "Pclass           0    0.000000\n",
      "Name             0    0.000000\n",
      "Sex              0    0.000000\n",
      "Age            177   19.865320\n",
      "SibSp            0    0.000000\n",
      "Parch            0    0.000000\n",
      "Ticket           0    0.000000\n",
      "Fare             0    0.000000\n",
      "Cabin          687   77.104377\n",
      "Embarked         2    0.224467\n"
     ]
    }
   ],
   "source": [
    "missing_values = titanic_df.isnull().sum()\n",
    "percentage_missing = (missing_values / len(titanic_df)) * 100\n",
    "print(\"\\nMissing values for each feature:\")\n",
    "print(pd.concat([missing_values, percentage_missing], axis=1, keys=['Total', 'Percentage']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Handling Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objective: Implement strategies to handle missing values in the Titanic dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the dimension of dataset using the .shape() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dimensions of the dataset: (891, 12)\n"
     ]
    }
   ],
   "source": [
    "print(\"Original dimensions of the dataset:\", titanic_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine the percentage of missing values for each feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Percentage of missing values in each feature:\n",
      "PassengerId     0.000000\n",
      "Survived        0.000000\n",
      "Pclass          0.000000\n",
      "Name            0.000000\n",
      "Sex             0.000000\n",
      "Age            19.865320\n",
      "SibSp           0.000000\n",
      "Parch           0.000000\n",
      "Ticket          0.000000\n",
      "Fare            0.000000\n",
      "Cabin          77.104377\n",
      "Embarked        0.224467\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "percentage_missing = (titanic_df.isnull().sum() / len(titanic_df)) * 100\n",
    "print(\"\\nPercentage of missing values in each feature:\")\n",
    "print(percentage_missing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove the missing values from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df = titanic_df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Again, check the number of missing values in dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions after removing missing values: (183, 12)\n"
     ]
    }
   ],
   "source": [
    "print(\"Dimensions after removing missing values:\", titanic_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for duplicate values in the dataset and display the number of duplicate rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows: 0\n"
     ]
    }
   ],
   "source": [
    "duplicate_rows = titanic_df.duplicated()\n",
    "print(\"Number of duplicate rows:\", duplicate_rows.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove the duplicate rows from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df = titanic_df[~duplicate_rows]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Again, display the number of rows of data frame to verify the duplicate values are removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions after removing duplicates: (183, 12)\n"
     ]
    }
   ],
   "source": [
    "print(\"Dimensions after removing duplicates:\", titanic_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Descriptive Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objective: Calculate and interpret descriptive statistics to gain insights into the Titanic dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate basic summary statistics - describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary statistics for numerical features:\n",
      "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
      "count   183.000000  183.000000  183.000000  183.000000  183.000000   \n",
      "mean    455.366120    0.672131    1.191257   35.674426    0.464481   \n",
      "std     247.052476    0.470725    0.515187   15.643866    0.644159   \n",
      "min       2.000000    0.000000    1.000000    0.920000    0.000000   \n",
      "25%     263.500000    0.000000    1.000000   24.000000    0.000000   \n",
      "50%     457.000000    1.000000    1.000000   36.000000    0.000000   \n",
      "75%     676.000000    1.000000    1.000000   47.500000    1.000000   \n",
      "max     890.000000    1.000000    3.000000   80.000000    3.000000   \n",
      "\n",
      "            Parch        Fare  \n",
      "count  183.000000  183.000000  \n",
      "mean     0.475410   78.682469  \n",
      "std      0.754617   76.347843  \n",
      "min      0.000000    0.000000  \n",
      "25%      0.000000   29.700000  \n",
      "50%      0.000000   57.000000  \n",
      "75%      1.000000   90.000000  \n",
      "max      4.000000  512.329200  \n"
     ]
    }
   ],
   "source": [
    "print(\"Summary statistics for numerical features:\")\n",
    "print(titanic_df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the basic summary statistics - quantile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantiles for numerical features:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'str' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mf:\\AI with Irfan Malik\\Lecture Code\\Assignments Solved\\Assignment_06.ipynb Cell 41\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/AI%20with%20Irfan%20Malik/Lecture%20Code/Assignments%20Solved/Assignment_06.ipynb#X62sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mQuantiles for numerical features:\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/f%3A/AI%20with%20Irfan%20Malik/Lecture%20Code/Assignments%20Solved/Assignment_06.ipynb#X62sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(titanic_df\u001b[39m.\u001b[39;49mquantile([\u001b[39m0.25\u001b[39;49m, \u001b[39m0.5\u001b[39;49m, \u001b[39m0.75\u001b[39;49m]))\n",
      "File \u001b[1;32mc:\\Users\\nabee\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:10927\u001b[0m, in \u001b[0;36mDataFrame.quantile\u001b[1;34m(self, q, axis, numeric_only, interpolation, method)\u001b[0m\n\u001b[0;32m  10923\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m  10924\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInvalid method: \u001b[39m\u001b[39m{\u001b[39;00mmethod\u001b[39m}\u001b[39;00m\u001b[39m. Method must be in \u001b[39m\u001b[39m{\u001b[39;00mvalid_method\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m  10925\u001b[0m     )\n\u001b[0;32m  10926\u001b[0m \u001b[39mif\u001b[39;00m method \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39msingle\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m> 10927\u001b[0m     res \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39;49m_mgr\u001b[39m.\u001b[39;49mquantile(qs\u001b[39m=\u001b[39;49mq, axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, interpolation\u001b[39m=\u001b[39;49minterpolation)\n\u001b[0;32m  10928\u001b[0m \u001b[39melif\u001b[39;00m method \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtable\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m  10929\u001b[0m     valid_interpolation \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mnearest\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mlower\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mhigher\u001b[39m\u001b[39m\"\u001b[39m}\n",
      "File \u001b[1;32mc:\\Users\\nabee\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1587\u001b[0m, in \u001b[0;36mBlockManager.quantile\u001b[1;34m(self, qs, axis, interpolation)\u001b[0m\n\u001b[0;32m   1584\u001b[0m new_axes \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxes)\n\u001b[0;32m   1585\u001b[0m new_axes[\u001b[39m1\u001b[39m] \u001b[39m=\u001b[39m Index(qs, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mfloat64)\n\u001b[1;32m-> 1587\u001b[0m blocks \u001b[39m=\u001b[39m [\n\u001b[0;32m   1588\u001b[0m     blk\u001b[39m.\u001b[39;49mquantile(axis\u001b[39m=\u001b[39;49maxis, qs\u001b[39m=\u001b[39;49mqs, interpolation\u001b[39m=\u001b[39;49minterpolation)\n\u001b[0;32m   1589\u001b[0m     \u001b[39mfor\u001b[39;49;00m blk \u001b[39min\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mblocks\n\u001b[0;32m   1590\u001b[0m ]\n\u001b[0;32m   1592\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)(blocks, new_axes)\n",
      "File \u001b[1;32mc:\\Users\\nabee\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1588\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1584\u001b[0m new_axes \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxes)\n\u001b[0;32m   1585\u001b[0m new_axes[\u001b[39m1\u001b[39m] \u001b[39m=\u001b[39m Index(qs, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mfloat64)\n\u001b[0;32m   1587\u001b[0m blocks \u001b[39m=\u001b[39m [\n\u001b[1;32m-> 1588\u001b[0m     blk\u001b[39m.\u001b[39;49mquantile(axis\u001b[39m=\u001b[39;49maxis, qs\u001b[39m=\u001b[39;49mqs, interpolation\u001b[39m=\u001b[39;49minterpolation)\n\u001b[0;32m   1589\u001b[0m     \u001b[39mfor\u001b[39;00m blk \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mblocks\n\u001b[0;32m   1590\u001b[0m ]\n\u001b[0;32m   1592\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)(blocks, new_axes)\n",
      "File \u001b[1;32mc:\\Users\\nabee\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:1463\u001b[0m, in \u001b[0;36mBlock.quantile\u001b[1;34m(self, qs, interpolation, axis)\u001b[0m\n\u001b[0;32m   1460\u001b[0m \u001b[39massert\u001b[39;00m axis \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m  \u001b[39m# only ever called this way\u001b[39;00m\n\u001b[0;32m   1461\u001b[0m \u001b[39massert\u001b[39;00m is_list_like(qs)  \u001b[39m# caller is responsible for this\u001b[39;00m\n\u001b[1;32m-> 1463\u001b[0m result \u001b[39m=\u001b[39m quantile_compat(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvalues, np\u001b[39m.\u001b[39;49masarray(qs\u001b[39m.\u001b[39;49m_values), interpolation)\n\u001b[0;32m   1464\u001b[0m \u001b[39m# ensure_block_shape needed for cases where we start with EA and result\u001b[39;00m\n\u001b[0;32m   1465\u001b[0m \u001b[39m#  is ndarray, e.g. IntegerArray, SparseArray\u001b[39;00m\n\u001b[0;32m   1466\u001b[0m result \u001b[39m=\u001b[39m ensure_block_shape(result, ndim\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\nabee\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\array_algos\\quantile.py:37\u001b[0m, in \u001b[0;36mquantile_compat\u001b[1;34m(values, qs, interpolation)\u001b[0m\n\u001b[0;32m     35\u001b[0m     fill_value \u001b[39m=\u001b[39m na_value_for_dtype(values\u001b[39m.\u001b[39mdtype, compat\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m     36\u001b[0m     mask \u001b[39m=\u001b[39m isna(values)\n\u001b[1;32m---> 37\u001b[0m     \u001b[39mreturn\u001b[39;00m quantile_with_mask(values, mask, fill_value, qs, interpolation)\n\u001b[0;32m     38\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     39\u001b[0m     \u001b[39mreturn\u001b[39;00m values\u001b[39m.\u001b[39m_quantile(qs, interpolation)\n",
      "File \u001b[1;32mc:\\Users\\nabee\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\array_algos\\quantile.py:95\u001b[0m, in \u001b[0;36mquantile_with_mask\u001b[1;34m(values, mask, fill_value, qs, interpolation)\u001b[0m\n\u001b[0;32m     93\u001b[0m     result \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrepeat(flat, \u001b[39mlen\u001b[39m(values))\u001b[39m.\u001b[39mreshape(\u001b[39mlen\u001b[39m(values), \u001b[39mlen\u001b[39m(qs))\n\u001b[0;32m     94\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 95\u001b[0m     result \u001b[39m=\u001b[39m _nanpercentile(\n\u001b[0;32m     96\u001b[0m         values,\n\u001b[0;32m     97\u001b[0m         qs \u001b[39m*\u001b[39;49m \u001b[39m100.0\u001b[39;49m,\n\u001b[0;32m     98\u001b[0m         na_value\u001b[39m=\u001b[39;49mfill_value,\n\u001b[0;32m     99\u001b[0m         mask\u001b[39m=\u001b[39;49mmask,\n\u001b[0;32m    100\u001b[0m         interpolation\u001b[39m=\u001b[39;49minterpolation,\n\u001b[0;32m    101\u001b[0m     )\n\u001b[0;32m    103\u001b[0m     result \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(result, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    104\u001b[0m     result \u001b[39m=\u001b[39m result\u001b[39m.\u001b[39mT\n",
      "File \u001b[1;32mc:\\Users\\nabee\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\array_algos\\quantile.py:216\u001b[0m, in \u001b[0;36m_nanpercentile\u001b[1;34m(values, qs, na_value, mask, interpolation)\u001b[0m\n\u001b[0;32m    214\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n\u001b[0;32m    215\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 216\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39;49mpercentile(\n\u001b[0;32m    217\u001b[0m         values,\n\u001b[0;32m    218\u001b[0m         qs,\n\u001b[0;32m    219\u001b[0m         axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[0;32m    220\u001b[0m         \u001b[39m# error: No overload variant of \"percentile\" matches argument types\u001b[39;49;00m\n\u001b[0;32m    221\u001b[0m         \u001b[39m# \"ndarray[Any, Any]\", \"ndarray[Any, dtype[floating[_64Bit]]]\",\u001b[39;49;00m\n\u001b[0;32m    222\u001b[0m         \u001b[39m# \"int\", \"Dict[str, str]\"  [call-overload]\u001b[39;49;00m\n\u001b[0;32m    223\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m{np_percentile_argname: interpolation},  \u001b[39m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[0;32m    224\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\nabee\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:4283\u001b[0m, in \u001b[0;36mpercentile\u001b[1;34m(a, q, axis, out, overwrite_input, method, keepdims, interpolation)\u001b[0m\n\u001b[0;32m   4281\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m _quantile_is_valid(q):\n\u001b[0;32m   4282\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mPercentiles must be in the range [0, 100]\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 4283\u001b[0m \u001b[39mreturn\u001b[39;00m _quantile_unchecked(\n\u001b[0;32m   4284\u001b[0m     a, q, axis, out, overwrite_input, method, keepdims)\n",
      "File \u001b[1;32mc:\\Users\\nabee\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:4555\u001b[0m, in \u001b[0;36m_quantile_unchecked\u001b[1;34m(a, q, axis, out, overwrite_input, method, keepdims)\u001b[0m\n\u001b[0;32m   4547\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_quantile_unchecked\u001b[39m(a,\n\u001b[0;32m   4548\u001b[0m                         q,\n\u001b[0;32m   4549\u001b[0m                         axis\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4552\u001b[0m                         method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mlinear\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   4553\u001b[0m                         keepdims\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m   4554\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Assumes that q is in [0, 1], and is an ndarray\"\"\"\u001b[39;00m\n\u001b[1;32m-> 4555\u001b[0m     \u001b[39mreturn\u001b[39;00m _ureduce(a,\n\u001b[0;32m   4556\u001b[0m                     func\u001b[39m=\u001b[39;49m_quantile_ureduce_func,\n\u001b[0;32m   4557\u001b[0m                     q\u001b[39m=\u001b[39;49mq,\n\u001b[0;32m   4558\u001b[0m                     keepdims\u001b[39m=\u001b[39;49mkeepdims,\n\u001b[0;32m   4559\u001b[0m                     axis\u001b[39m=\u001b[39;49maxis,\n\u001b[0;32m   4560\u001b[0m                     out\u001b[39m=\u001b[39;49mout,\n\u001b[0;32m   4561\u001b[0m                     overwrite_input\u001b[39m=\u001b[39;49moverwrite_input,\n\u001b[0;32m   4562\u001b[0m                     method\u001b[39m=\u001b[39;49mmethod)\n",
      "File \u001b[1;32mc:\\Users\\nabee\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:3823\u001b[0m, in \u001b[0;36m_ureduce\u001b[1;34m(a, func, keepdims, **kwargs)\u001b[0m\n\u001b[0;32m   3820\u001b[0m             index_out \u001b[39m=\u001b[39m (\u001b[39m0\u001b[39m, ) \u001b[39m*\u001b[39m nd\n\u001b[0;32m   3821\u001b[0m             kwargs[\u001b[39m'\u001b[39m\u001b[39mout\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m out[(\u001b[39mEllipsis\u001b[39m, ) \u001b[39m+\u001b[39m index_out]\n\u001b[1;32m-> 3823\u001b[0m r \u001b[39m=\u001b[39m func(a, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   3825\u001b[0m \u001b[39mif\u001b[39;00m out \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   3826\u001b[0m     \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Users\\nabee\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:4721\u001b[0m, in \u001b[0;36m_quantile_ureduce_func\u001b[1;34m(a, q, axis, out, overwrite_input, method)\u001b[0m\n\u001b[0;32m   4719\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   4720\u001b[0m         arr \u001b[39m=\u001b[39m a\u001b[39m.\u001b[39mcopy()\n\u001b[1;32m-> 4721\u001b[0m result \u001b[39m=\u001b[39m _quantile(arr,\n\u001b[0;32m   4722\u001b[0m                    quantiles\u001b[39m=\u001b[39;49mq,\n\u001b[0;32m   4723\u001b[0m                    axis\u001b[39m=\u001b[39;49maxis,\n\u001b[0;32m   4724\u001b[0m                    method\u001b[39m=\u001b[39;49mmethod,\n\u001b[0;32m   4725\u001b[0m                    out\u001b[39m=\u001b[39;49mout)\n\u001b[0;32m   4726\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\nabee\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:4840\u001b[0m, in \u001b[0;36m_quantile\u001b[1;34m(arr, quantiles, axis, method, out)\u001b[0m\n\u001b[0;32m   4838\u001b[0m     result_shape \u001b[39m=\u001b[39m virtual_indexes\u001b[39m.\u001b[39mshape \u001b[39m+\u001b[39m (\u001b[39m1\u001b[39m,) \u001b[39m*\u001b[39m (arr\u001b[39m.\u001b[39mndim \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[0;32m   4839\u001b[0m     gamma \u001b[39m=\u001b[39m gamma\u001b[39m.\u001b[39mreshape(result_shape)\n\u001b[1;32m-> 4840\u001b[0m     result \u001b[39m=\u001b[39m _lerp(previous,\n\u001b[0;32m   4841\u001b[0m                    \u001b[39mnext\u001b[39;49m,\n\u001b[0;32m   4842\u001b[0m                    gamma,\n\u001b[0;32m   4843\u001b[0m                    out\u001b[39m=\u001b[39;49mout)\n\u001b[0;32m   4844\u001b[0m \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39many(slices_having_nans):\n\u001b[0;32m   4845\u001b[0m     \u001b[39mif\u001b[39;00m result\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m out \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   4846\u001b[0m         \u001b[39m# can't write to a scalar, but indexing will be correct\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\nabee\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:4655\u001b[0m, in \u001b[0;36m_lerp\u001b[1;34m(a, b, t, out)\u001b[0m\n\u001b[0;32m   4641\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_lerp\u001b[39m(a, b, t, out\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m   4642\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   4643\u001b[0m \u001b[39m    Compute the linear interpolation weighted by gamma on each point of\u001b[39;00m\n\u001b[0;32m   4644\u001b[0m \u001b[39m    two same shape array.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4653\u001b[0m \u001b[39m        Output array.\u001b[39;00m\n\u001b[0;32m   4654\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4655\u001b[0m     diff_b_a \u001b[39m=\u001b[39m subtract(b, a)\n\u001b[0;32m   4656\u001b[0m     \u001b[39m# asanyarray is a stop-gap until gh-13105\u001b[39;00m\n\u001b[0;32m   4657\u001b[0m     lerp_interpolation \u001b[39m=\u001b[39m asanyarray(add(a, diff_b_a \u001b[39m*\u001b[39m t, out\u001b[39m=\u001b[39mout))\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'str' and 'str'"
     ]
    }
   ],
   "source": [
    "print(\"\\nQuantiles for numerical features:\")\n",
    "print(titanic_df.quantile([0.25, 0.5, 0.75]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the correlation matrix for all numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = titanic_df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the correlation matrix using a heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5)\n",
    "plt.title(\"Correlation Matrix\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
