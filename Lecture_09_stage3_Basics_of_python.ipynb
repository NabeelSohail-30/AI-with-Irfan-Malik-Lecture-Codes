{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Hope to Skills - Free AI Course**\n",
        "This note book cover the following concepts\n",
        "\n",
        "1. Use cases of openai API\n",
        "2. Hugging Face\n",
        "3. Hugging Face Pipeline\n"
      ],
      "metadata": {
        "id": "VG6wE0Q9U17m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Using the open.ai key in the code**\n",
        "to generate the key you can go to the link\n",
        "https://platform.openai.com/account/api-keys\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "otQHIvrmQF6S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "id": "Qmf9x_U_wjRs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "openai.api_key = 'your open ai key'"
      ],
      "metadata": {
        "id": "yfLEmcp7QS-7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Image Generation Using Openai**\n"
      ],
      "metadata": {
        "id": "LuJdbnT6VAOq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To learn more you can visit the link https://platform.openai.com/docs/guides/images/usage\n"
      ],
      "metadata": {
        "id": "0Yle12qI34O5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "id": "mve8k0RrT4io"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can generate images using the openai API. The Tool for that is Called **Dall-e**\n"
      ],
      "metadata": {
        "id": "CAVkwdSmVf2-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "DALLÂ·E has the ability to understand and follow detailed instructions for generating images."
      ],
      "metadata": {
        "id": "ZvQ1H4ZNXNqf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "EhwELxiVkqZB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "import openai\n",
        "import requests\n",
        "import PIL\n",
        "from PIL import Image\n",
        "\n",
        "openai.api_key = 'your openai key'\n",
        "\n",
        "def generate_image(text):\n",
        "    # Generate the image using OpenAI's DALL-E model\n",
        "    response = openai.Image.create(\n",
        "        prompt=text,\n",
        "        n=1,\n",
        "        size = \"512x512\"\n",
        "        )\n",
        "\n",
        "    # Get the image URL from the response\n",
        "    image_url = response.data[0]['url']\n",
        "\n",
        "    # Download the image and convert it to a PIL image\n",
        "    image_content = requests.get(image_url).content\n",
        "    image = Image.open(io.BytesIO(image_content))\n",
        "    image.show()"
      ],
      "metadata": {
        "id": "52k0KG4nRQAo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = input(\"Enter your prompt to generate the image: \")\n",
        "generate_image(prompt)\n",
        "# print(type(output))\n"
      ],
      "metadata": {
        "id": "t2Dqaj8kRRVW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TTqTgRbyZtWY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Hugging Face**\n"
      ],
      "metadata": {
        "id": "KL5Aai5kN5c_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Installing the required modules\n",
        "!pip install transformers"
      ],
      "metadata": {
        "id": "paJV809SLO4W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Installing the required modules\n",
        "!pip install datasets"
      ],
      "metadata": {
        "id": "kBCcCZVhLZIZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Text Classification**\n",
        "\n",
        "We can classify the text using the Hugging face prebuit pipelines\n",
        "we will extensively use **pipline()**"
      ],
      "metadata": {
        "id": "FY0gQaB0juMp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Sentiment Analysis**"
      ],
      "metadata": {
        "id": "IBxquZRGkbER"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "from transformers import pipeline\n",
        "\n",
        "pipe = pipeline(\"text-classification\")\n",
        "pipe(\"This movie is very boring\")"
      ],
      "metadata": {
        "id": "CDpEI0rJKpQT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "from transformers import pipeline\n",
        "\n",
        "pipe = pipeline(model=\"roberta-large-mnli\")\n",
        "pipe(\"I do not like this movie\")"
      ],
      "metadata": {
        "id": "ANV_G8Gp9MHx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**We can also pass the string in the form of list**"
      ],
      "metadata": {
        "id": "zKl7fqHCmsl5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# pipeline for text classification\n",
        "\n",
        "pipe = pipeline(\"sentiment-analysis\")\n",
        "pipe([\"This restaurant is awesome\", \"This restaurant is awful\"])"
      ],
      "metadata": {
        "id": "3L3_MkqVbUHZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Text Summrization**\n",
        "\n",
        "we can summarize the text using the hugging face pipline\n",
        "for that we need to pass the pipeline the parameter as \"summarization\""
      ],
      "metadata": {
        "id": "lZWHaYdnm-9x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# text to be summarized\n",
        "input_text = \"Start by providing your text input. It could be a sentence or a paragraph.\\n Tokenization: The input is tokenized, which means breaking it down into smaller units like words or subwords.\\n Tokens are the building blocks for NLP models\\n.Model: The tokenized input is passed through a pre-trained NLP model. \\n Hugging Face offers a wide range of models for different NLP tasks, such as sentiment analysis,\\n  question answering, and text generation.Prediction/Output: The model processes the tokenized input and generates \\n a prediction or output specific to the task. For example, if it's sentiment analysis, \\n it could predict whether the input is positive or negative\"\n",
        "print(input_text)"
      ],
      "metadata": {
        "id": "0OZyfkDb5FGM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# use bart in pytorch\n",
        "summarizer = pipeline(\"summarization\")\n",
        "summarizer(\"Text Input: Start by providing your text input. It could be a sentence or a paragraph.Tokenization: The input is tokenized, which means breaking it down into smaller units like words or subwords. Tokens are the building blocks for NLP models.Model: The tokenized input is passed through a pre-trained NLP model. Hugging Face offers a wide range of models for different NLP tasks, such as sentiment analysis, question answering, and text generation.Prediction/Output: The model processes the tokenized input and generates a prediction or output specific to the task. For example, if it's sentiment analysis, it could predict whether the input is positive or negative.\", min_length=5, max_length=30)"
      ],
      "metadata": {
        "id": "PQBF3E3ag2xZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Name Entity Relation**\n",
        "\n",
        "Named Entity Recognition is a natural language processing (NLP) task\n",
        "\n",
        "that involves identifying and classifying named entities in text into\n",
        "\n",
        "predefined categories such as person names, organizations, locations, dates, and more.\n"
      ],
      "metadata": {
        "id": "zMYDAtZNnwai"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = pipeline(\"ner\")\n",
        "example = \"My name is Ahmad and i am going to Pakistan\"\n",
        "\n",
        "ner_results = nlp(example)\n",
        "print(ner_results)\n"
      ],
      "metadata": {
        "id": "L11EYoZ0lrXD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Image Classification**"
      ],
      "metadata": {
        "id": "B2kLc7zHpS6a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To use this pipline download the image in PNG format.\n",
        "\n",
        "Click on the folder icon on the left side panel.\n",
        "\n",
        "Upload the image and copy its path in the code"
      ],
      "metadata": {
        "id": "i5VmiyYdGfW7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Displaying the image\n",
        "from PIL import Image\n",
        "\n",
        "# Specify the path to your PNG image\n",
        "image_path = '/content/demo.png'\n",
        "\n",
        "# Open the image using PIL\n",
        "image = Image.open(image_path)\n",
        "\n",
        "# Display the image\n",
        "image.show()\n"
      ],
      "metadata": {
        "id": "Gz7c8Ud2pnXq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "classifier = pipeline(model=\"microsoft/beit-base-patch16-224-pt22k-ft22k\")\n",
        "classifier(\"/content/demo.png\")"
      ],
      "metadata": {
        "id": "zyJCi71BcXwQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install diffusers"
      ],
      "metadata": {
        "id": "t0P2M4IMZzCQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "sEim0_1xaNR7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "from transformers import pipeline\n",
        "from diffusers import StableDiffusionPipeline\n",
        "import torch\n",
        "\n",
        "model_id = \"runwayml/stable-diffusion-v1-5\"\n",
        "pipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16)\n",
        "pipe = pipe.to(\"cuda\")\n",
        "\n",
        "prompt = \"a photo of an astronaut riding a horse on mars\"\n",
        "image = pipe(prompt).images[0]\n",
        "\n",
        "image.save(\"astronaut_rides_horse.png\")\n"
      ],
      "metadata": {
        "id": "O_2vJANCZuYY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}